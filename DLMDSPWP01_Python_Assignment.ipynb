{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27DDsu6Fk51V",
        "outputId": "380e86b4-8091-46a4-ac45-404f5e67d4a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.12/dist-packages (2.0.43)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.12/dist-packages (3.7.3)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (8.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (3.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (4.15.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.12/dist-packages (from bokeh) (3.1.6)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.12/dist-packages (from bokeh) (1.3.3)\n",
            "Requirement already satisfied: narwhals>=1.13 in /usr/local/lib/python3.12/dist-packages (from bokeh) (2.3.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.12/dist-packages (from bokeh) (25.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from bokeh) (11.3.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.12/dist-packages (from bokeh) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from bokeh) (6.4.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.12/dist-packages (from bokeh) (2025.4.0)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest) (2.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=2.9->bokeh) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install pandas numpy sqlalchemy bokeh pytest\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define global paths"
      ],
      "metadata": {
        "id": "-rG6SaWmlxOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_CSV = 'train.csv'\n",
        "IDEAL_CSV = 'ideal.csv'\n",
        "TEST_CSV = 'test.csv'\n",
        "DB_PATH = 'results.db'\n",
        "EXPORT_MAPPING_CSV = 'test_mapping.csv'\n",
        "BOKEH_HTML = 'visualization.html'\n"
      ],
      "metadata": {
        "id": "zZTKip7LluJd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "VOFxuq2el4gI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.exc import SQLAlchemyError\n",
        "from bokeh.plotting import figure, output_file, save\n",
        "from bokeh.models import ColumnDataSource, HoverTool\n",
        "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')"
      ],
      "metadata": {
        "id": "2Pcoqsa2lzv2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Exceptions"
      ],
      "metadata": {
        "id": "kjExwMIQmCT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataFormatError(Exception):\n",
        "    \"\"\"Raised when input CSV format is not as expected.\"\"\"\n",
        "    pass\n",
        "class DatabaseError(Exception):\n",
        "    \"\"\"Raised for database-related errors.\"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "27zAXFRAmGA2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Classes"
      ],
      "metadata": {
        "id": "3SYHm2fFm6p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseDataset:\n",
        "    def __init__(self, path: str):\n",
        "        self.path = path\n",
        "        self.df: Optional[pd.DataFrame] = None\n",
        "\n",
        "    def load(self):\n",
        "        try:\n",
        "            self.df = pd.read_csv(self.path)\n",
        "        except Exception as e:\n",
        "            raise DataFormatError(f'Could not read CSV at {self.path}: {e}')\n",
        "        return self.df\n",
        "class TrainingDataset(BaseDataset):\n",
        "    \"\"\"\n",
        "    Training dataset; expects X and 4 Y columns (Y1..Y4).\n",
        "    Demonstrates inheritance from BaseDataset.\n",
        "    \"\"\"\n",
        "    def validate(self):\n",
        "        if self.df is None:\n",
        "            raise DataFormatError('Training data not loaded yet.')\n",
        "        cols = list(self.df.columns)\n",
        "        if len(cols) < 5:\n",
        "            raise DataFormatError('Training CSV must contain at least 5 columns: X and 4 Ys.')\n",
        "        # Ensure first column is X\n",
        "        # We'll accept columns starting with X or x\n",
        "        if cols[0].lower() != 'x':\n",
        "            logging.warning('First column not named X â€” treating first column as X anyway.')\n",
        "\n",
        "    def get_x(self) -> np.ndarray:\n",
        "        return self.df.iloc[:, 0].values\n",
        "\n",
        "    def get_y_columns(self) -> List[str]:\n",
        "        return list(self.df.columns[1:5])\n",
        "\n",
        "    def get_training_series(self) -> Dict[str, pd.Series]:\n",
        "        \"\"\"Return mapping of training column name -> series\"\"\"\n",
        "        cols = self.get_y_columns()\n",
        "        return {c: self.df[c] for c in cols}\n",
        "\n",
        "\n",
        "class IdealFunctions(BaseDataset):\n",
        "    \"\"\"Loads ideal functions CSV (X + 50 columns).\"\"\"\n",
        "    def validate(self):\n",
        "        if self.df is None:\n",
        "            raise DataFormatError('Ideal functions not loaded yet.')\n",
        "        if self.df.shape[1] < 2:\n",
        "            raise DataFormatError('Ideal CSV must contain X and at least one ideal function column.')\n",
        "\n",
        "    def get_x(self) -> np.ndarray:\n",
        "        return self.df.iloc[:, 0].values\n",
        "\n",
        "    def get_function_columns(self) -> List[str]:\n",
        "        return list(self.df.columns[1:])\n",
        "\n",
        "    def get_function_series(self, name: str) -> pd.Series:\n",
        "        return self.df[name]\n",
        "\n",
        "\n",
        "class TestDataset(BaseDataset):\n",
        "    \"\"\"Loads test CSV with X,Y pairs.\"\"\"\n",
        "    def validate(self):\n",
        "        if self.df is None:\n",
        "            raise DataFormatError('Test data not loaded yet.')\n",
        "        if self.df.shape[1] < 2:\n",
        "            raise DataFormatError('Test CSV must contain X and Y columns.')\n",
        "\n",
        "    def get_pairs(self) -> List[Tuple[float, float]]:\n",
        "        xs = self.df.iloc[:, 0].values\n",
        "        ys = self.df.iloc[:, 1].values\n",
        "        return list(zip(xs, ys))\n"
      ],
      "metadata": {
        "id": "LU1nZqFmmm_a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Database Manager"
      ],
      "metadata": {
        "id": "JhIa9JQan83a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Database Manager\n",
        "class DatabaseManager:\n",
        "    \"\"\"Handles SQLite DB creation and table writes using sqlalchemy.\"\"\"\n",
        "\n",
        "    def __init__(self, db_path: str = DB_PATH):\n",
        "        self.db_path = db_path\n",
        "        self.engine = None\n",
        "\n",
        "    def connect(self):\n",
        "        try:\n",
        "            self.engine = create_engine(f'sqlite:///{self.db_path}')\n",
        "            logging.info(f'Connected to SQLite DB at {self.db_path}')\n",
        "        except SQLAlchemyError as e:\n",
        "            raise DatabaseError(f'Could not create DB engine: {e}')\n",
        "\n",
        "    def write_dataframe(self, df: pd.DataFrame, table_name: str, if_exists='replace'):\n",
        "        if self.engine is None:\n",
        "            self.connect()\n",
        "        try:\n",
        "            df.to_sql(table_name, con=self.engine, index=False, if_exists=if_exists)\n",
        "            logging.info(f'Wrote table {table_name} (rows: {len(df)})')\n",
        "        except Exception as e:\n",
        "            raise DatabaseError(f'Failed to write table {table_name}: {e}')\n"
      ],
      "metadata": {
        "id": "HFt-d3gNnAMO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Core Mapping Logic"
      ],
      "metadata": {
        "id": "PIir32fkoXUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Mapper:\n",
        "    def __init__(self, training: TrainingDataset, ideal: IdealFunctions):\n",
        "        self.training = training\n",
        "        self.ideal = ideal\n",
        "        # Will contain mapping from training col -> chosen ideal col\n",
        "        self.chosen_map: Dict[str, str] = {}\n",
        "        # Largest deviations per training col\n",
        "        self.max_training_deviation: Dict[str, float] = {}\n",
        "\n",
        "    def choose_best_ideal_for_each_training(self):\n",
        "        \"\"\"For each training Y column, find the ideal function column minimizing sum of squared deviations.\"\"\"\n",
        "        x_train = self.training.get_x()\n",
        "        ideal_x = self.ideal.get_x()\n",
        "        # Basic check: x grids should align. If not, align by index.\n",
        "        if not np.array_equal(x_train, ideal_x):\n",
        "            logging.warning('X-values of training and ideal functions do not match exactly. Aligning by index.')\n",
        "\n",
        "        ideal_cols = self.ideal.get_function_columns()\n",
        "        for tcol in self.training.get_y_columns():\n",
        "            y_train = self.training.df[tcol].values\n",
        "            best_col = None\n",
        "            best_ssq = float('inf')\n",
        "            best_residuals = None\n",
        "\n",
        "            for icol in ideal_cols:\n",
        "                y_ideal = self.ideal.df[icol].values\n",
        "                # resize if lengths differ\n",
        "                n = min(len(y_train), len(y_ideal))\n",
        "                resid = y_train[:n] - y_ideal[:n]\n",
        "                ssq = np.sum(resid ** 2)\n",
        "                if ssq < best_ssq:\n",
        "                    best_ssq = ssq\n",
        "                    best_col = icol\n",
        "                    best_residuals = resid\n",
        "\n",
        "            self.chosen_map[tcol] = best_col\n",
        "            # largest absolute deviation\n",
        "            self.max_training_deviation[tcol] = float(np.max(np.abs(best_residuals)))\n",
        "            logging.info(\n",
        "                f'Training {tcol} matched to ideal {best_col} '\n",
        "                f'with max dev {self.max_training_deviation[tcol]:.6f}'\n",
        "            )\n",
        "        return self.chosen_map\n",
        "\n",
        "    def map_test_points(self, test_pairs: List[Tuple[float, float]]) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Map each test point to one of the chosen ideal functions if within threshold.\n",
        "        Threshold per training = max_training_deviation * sqrt(2).\n",
        "        Returns DataFrame with columns: X, Y, DeltaY, AssignedFunction (or None)\n",
        "        \"\"\"\n",
        "        rows = []\n",
        "        # Build reverse map: ideal col -> training col\n",
        "        reverse_map = {v: k for k, v in self.chosen_map.items()}\n",
        "\n",
        "        for x_val, y_val in test_pairs:\n",
        "            best_ideal = None\n",
        "            best_delta = float('inf')\n",
        "            # For each chosen ideal (4 of them)\n",
        "            for tcol, icol in self.chosen_map.items():\n",
        "                ideal_df = self.ideal.df\n",
        "                try:\n",
        "                    y_ideal = np.interp(x_val, ideal_df.iloc[:, 0].values, ideal_df[icol].values)\n",
        "                except Exception:\n",
        "                    y_ideal = float('nan')\n",
        "                delta = abs(y_val - y_ideal)\n",
        "                # threshold\n",
        "                threshold = self.max_training_deviation[tcol] * math.sqrt(2)\n",
        "                if delta <= threshold and delta < best_delta:\n",
        "                    best_delta = delta\n",
        "                    best_ideal = icol\n",
        "            rows.append({\n",
        "                'X': x_val,\n",
        "                'Y': y_val,\n",
        "                'DeltaY': (best_delta if best_ideal is not None else None),\n",
        "                'IdealFunction': (best_ideal if best_ideal is not None else None)\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(rows)\n",
        "        return df\n"
      ],
      "metadata": {
        "id": "6Xfb8-uDnDZ6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "M5UBSOpiojye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Visualizer:\n",
        "    \"\"\"Creates a Bokeh plot showing training data, chosen ideal functions, and mapped test points.\"\"\"\n",
        "\n",
        "    def __init__(self, training: TrainingDataset, ideal: IdealFunctions, test_df: pd.DataFrame, mapper: Mapper):\n",
        "        self.training = training\n",
        "        self.ideal = ideal\n",
        "        self.test_df = test_df\n",
        "        self.mapper = mapper\n",
        "\n",
        "    def create_plot(self, out_path: str = BOKEH_HTML):\n",
        "        output_file(out_path, title='Training, Ideal Functions and Test Mapping')\n",
        "        p = figure(\n",
        "            title='Training vs Chosen Ideal Functions and Test Points',\n",
        "            x_axis_label='X',\n",
        "            y_axis_label='Y',\n",
        "            width=1000,\n",
        "            height=600,\n",
        "            tools='pan,wheel_zoom,box_zoom,reset,save'\n",
        "        )\n",
        "\n",
        "        # Plot training series\n",
        "        x = self.training.get_x()\n",
        "        for tcol in self.training.get_y_columns():\n",
        "            p.line(x, self.training.df[tcol].values, legend_label=f'Train {tcol}', line_width=2)\n",
        "\n",
        "        # Plot chosen ideal functions\n",
        "        for tcol, icol in self.mapper.chosen_map.items():\n",
        "            ideal_x = self.ideal.get_x()\n",
        "            p.line(\n",
        "                ideal_x,\n",
        "                self.ideal.df[icol].values,\n",
        "                legend_label=f'Ideal {icol} (for {tcol})',\n",
        "                line_dash='dashed'\n",
        "            )\n",
        "\n",
        "        # Plot test points, colored by assignment\n",
        "        assigned = self.test_df.dropna(subset=['IdealFunction'])\n",
        "        unassigned = self.test_df[self.test_df['IdealFunction'].isna()]\n",
        "\n",
        "        if not assigned.empty:\n",
        "            src_assigned = ColumnDataSource(assigned)\n",
        "            p.circle('X', 'Y', source=src_assigned, size=8, legend_label='Assigned Test Points')\n",
        "\n",
        "        if not unassigned.empty:\n",
        "            src_un = ColumnDataSource(unassigned)\n",
        "            p.cross('X', 'Y', source=src_un, size=8, legend_label='Unassigned Test Points')\n",
        "\n",
        "        hover = HoverTool(tooltips=[('X', '@X'), ('Y', '@Y'), ('DeltaY', '@DeltaY'), ('IdealFunction', '@IdealFunction')])\n",
        "        p.add_tools(hover)\n",
        "\n",
        "        p.legend.location = 'top_left'\n",
        "        save(p)\n",
        "        logging.info(f'Bokeh visualization saved to {out_path}')\n"
      ],
      "metadata": {
        "id": "bEIy95vjonPs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilities and Unit Tests"
      ],
      "metadata": {
        "id": "6jdJ-0ZApk7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline(train_csv: str = TRAIN_CSV, ideal_csv: str = IDEAL_CSV, test_csv: str = TEST_CSV):\n",
        "    # Load training data\n",
        "    training = TrainingDataset(train_csv)\n",
        "    training.load()\n",
        "    training.validate()\n",
        "\n",
        "    # Load ideal functions\n",
        "    ideal = IdealFunctions(ideal_csv)\n",
        "    ideal.load()\n",
        "    ideal.validate()\n",
        "\n",
        "    # Load test data\n",
        "    test = TestDataset(test_csv)\n",
        "    test.load()\n",
        "    test.validate()\n",
        "\n",
        "    # DB manager\n",
        "    db = DatabaseManager()\n",
        "    db.connect()\n",
        "    # write raw tables\n",
        "    db.write_dataframe(training.df, 'training')\n",
        "    db.write_dataframe(ideal.df, 'ideal_functions')\n",
        "    db.write_dataframe(test.df, 'test_raw')\n",
        "\n",
        "    # Mapper\n",
        "    mapper = Mapper(training, ideal)\n",
        "    mapper.choose_best_ideal_for_each_training()\n",
        "    test_pairs = test.get_pairs()\n",
        "    mapping_df = mapper.map_test_points(test_pairs)\n",
        "\n",
        "    # Save mapping to DB and CSV\n",
        "    db.write_dataframe(mapping_df, 'test_mapping')\n",
        "    mapping_df.to_csv(EXPORT_MAPPING_CSV, index=False)\n",
        "    logging.info(f'Mapping exported to {EXPORT_MAPPING_CSV}')\n",
        "\n",
        "    # Visualization\n",
        "    viz = Visualizer(training, ideal, mapping_df, mapper)\n",
        "    viz.create_plot(BOKEH_HTML)\n",
        "\n",
        "    return {\n",
        "        'db_path': db.db_path,\n",
        "        'mapping_csv': EXPORT_MAPPING_CSV,\n",
        "        'bokeh_html': BOKEH_HTML,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "2_ag3MxBpkTk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit tests using assertions"
      ],
      "metadata": {
        "id": "Ss17hb2SqMPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def _unit_tests():\n",
        "    logging.info('Running basic unit tests...')\n",
        "\n",
        "    #  Check files exist\n",
        "    for p in [TRAIN_CSV, IDEAL_CSV, TEST_CSV]:\n",
        "        assert os.path.exists(p), f'Expected file not found: {p}'\n",
        "\n",
        "    #  Load and basic checks\n",
        "    tr = TrainingDataset(TRAIN_CSV)\n",
        "    tr.load()\n",
        "    tr.validate()\n",
        "\n",
        "    idf = IdealFunctions(IDEAL_CSV)\n",
        "    idf.load()\n",
        "    idf.validate()\n",
        "\n",
        "    te = TestDataset(TEST_CSV)\n",
        "    te.load()\n",
        "    te.validate()\n",
        "\n",
        "    #  Mapper choose logic\n",
        "    m = Mapper(tr, idf)\n",
        "    chosen = m.choose_best_ideal_for_each_training()\n",
        "    assert len(chosen) >= 1, 'No chosen mappings found.'\n",
        "\n",
        "    # Map test points\n",
        "    mapping_df = m.map_test_points(te.get_pairs())\n",
        "    assert 'IdealFunction' in mapping_df.columns, 'Mapping result missing IdealFunction column.'\n",
        "\n",
        "    logging.info('Unit tests passed (basic).')\n"
      ],
      "metadata": {
        "id": "r8rYfk8rqYbD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        _unit_tests()\n",
        "        results = run_pipeline()\n",
        "        logging.info('Pipeline completed successfully. Outputs:')\n",
        "        for k, v in results.items():\n",
        "            logging.info(f' - {k}: {v}')\n",
        "    except AssertionError as ae:\n",
        "        logging.error(f'AssertionError during tests/pipeline: {ae}')\n",
        "    except DataFormatError as dfe:\n",
        "        logging.error(f'Data format problem: {dfe}')\n",
        "    except DatabaseError as dbe:\n",
        "        logging.error(f'Database problem: {dbe}')\n",
        "    except Exception as e:\n",
        "        logging.exception(f'Unhandled exception: {e}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voiI1WGVqq3G",
        "outputId": "00fcf016-7357-4ebc-bdf7-983d87f27e91"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
            "BokehDeprecationWarning: 'cross() method' was deprecated in Bokeh 3.4.0 and will be removed, use \"scatter(marker='cross', ...) instead\" instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Connect to the DB\n",
        "conn = sqlite3.connect(\"results.db\")\n",
        "\n",
        "# Check which tables exist\n",
        "tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
        "print(\"Tables in DB:\")\n",
        "print(tables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xoe2VcIrvxM",
        "outputId": "c1d6acf4-c44e-42b1-d98d-5e7b0aa6e05e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables in DB:\n",
            "              name\n",
            "0         training\n",
            "1  ideal_functions\n",
            "2         test_raw\n",
            "3     test_mapping\n"
          ]
        }
      ]
    }
  ]
}